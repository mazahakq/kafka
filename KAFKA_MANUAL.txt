#Replication Factor - сообщение становится доступно для Consumer только если оно синхронизировано на заданное количество реплик
#Время опроса репликами лидера на наличие новых данных:
replica.fetch.wait.max.ms = 500 (default) - 200ms чаще
#Настройка producer-а:
acks (default = 1 обычно):
0  - Без подтверждения (Потеря данных возможна)
1  - Ожидаем только лидера (потеря данных в случае падения лидера и переизбрания лидера среди реплик)
-1 - Ожидаем лидера и все реплики (которые "in sync", т.е. считаются доступными), если все реплики в "out of sync" то аналогично параметру 1
#Помечает реплику в "out of sync" если она не успевает за указанное время принять сообщения
replica.max.lag.ms = 10000 (default) - 1000ms чаше
"out of sync" - Реплика считается не доступной на неё не отправляются сообщения (если лидер помрет, то она не станет лидером!)
"in sync" - Реплика успевает принмать сообщения
#Минимальное число реплик которые должны быть в статусе "in sync", если реплик таких нет, то сообщения не записываются
min.insync.replicas = 1 (default)
#Если true - параметр позволяет назначить "out of sync" реплики в лидера (потеря данных), Рекомендованное значение - false
#Подробнее про разбр проблем - https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals (KIP-106)
unclean.leader.election.enable = false (default)
#Кластер 3 брокера
Rf = 2, minISR = 1 - Доступность - ДА,  Надежность - НЕТ - Доступность при падении брокера, но возможна потеря данных
Rf = 2, minISR = 2 - Доступность - НЕТ, Надежность - ДА  - Если брокер упадет не будет возможности писать в кластер
Rf = 3, minISR = 2 - Доступность - ДА,  Надежность - ДА  - Копируем на все реплики, высокая нагрузка
#Кластер 5 брокеров более надежен и доступен.
#Перераспределение партиций: --throttle - Перераспределение партици для оптимизации времени!
kafka-reassign-partitions.sh
generate - Генерация карты партиций
execute - Перераспределение партиций
verify - Проверка текущего статуса
https://github.com/dimas/kafka-reassign-tool  - Скрипт ruby позволяет генериировать план перераспределения партиций:
https://github.com/linkedin/kafka-tools       - Мощные уттилиты для администрирования
Если процесс ломается лехем в zookeeper - удалить deleteall /kafka/admin/reassign_partitions - заново запускаем Перераспределение партиций.
#Удаление топика
delete.topic.enable = false (default) - kafka-topics.sh - Позволяет удалять топики если значение true, иначе удаление запрещено
1. Убеждаемся, что никто в топик не пишет и не читает
2. Переносим все партиции топика на один брокера
3. Удаляем на брокера партиции топика
4. Удаляем топик в zookeeper - deleteall /brokers/topics/name 
5. Перезагрузка брокера
#Создание топика осознано ставим параметры, лучше сделать скрипт который будет создавать топики с одинаковыми настройками!
#Логирование - https://habr.com/ru/company/badoo/blog/280606